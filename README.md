# üßÆ Verifica√ß√£o de N√∫meros Perfeitos e Amig√°veis em Intervalos Grandes

Este projeto tem como objetivo comparar a efici√™ncia das solu√ß√µes nas abordagens **sequencial**, **paralela** e **distribu√≠da** para a verifica√ß√£o de **n√∫meros perfeitos** e **pares de n√∫meros amig√°veis**, em grandes intervalos. Foi desenvolvido em linguagem **Java**, utilizando os ambientes de desenvolvimento **NetBeans** e **VS Code** para a implementa√ß√£o e execu√ß√£o.

## ‚ú® N√∫meros Perfeitos

N√∫meros perfeitos s√£o aqueles cuja soma de seus divisores - exceto ele mesmo - resulta no pr√≥prio n√∫mero.

**Exemplo:**  
- N√∫mero 28:
  - Divisores: 1, 2, 4, 7, 14, 28
  - Soma dos divisores (exceto ele mesmo): 1 + 2 + 4 + 7 + 14 = 28  
- Portanto, **28 √© um n√∫mero perfeito**.

### üìê Aplica√ß√£o de Euclides-Mersenne

Al√©m da verifica√ß√£o direta por meio da soma dos divisores, tamb√©m √© poss√≠vel utilizar o **Teorema de Euclides-Euler**, com a f√≥rmula de **Euclides-Mersenne**, que relaciona n√∫meros primos de Mersenne com n√∫meros perfeitos pares, para encontrar n√∫meros perfeitos.

Um **primo de Mersenne** √© um n√∫mero da forma:

> **M‚Çô = 2‚Åø ‚àí 1**, onde **n** tamb√©m √© primo.

Segundo o teorema, todo primo de Mersenne gera um n√∫mero perfeito par, pela f√≥rmula:

> **N = 2‚Åø‚Åª¬π √ó (2‚Åø ‚àí 1)**

**Exemplo:**  
Se **n = 3**, temos:  
- **M‚ÇÉ = 2¬≥ ‚àí 1 = 7** (primo de Mersenne)  
- N√∫mero perfeito: **N = 2¬≤ √ó 7 = 28**

Essa rela√ß√£o permite encontrar n√∫meros perfeitos de forma mais eficiente, sem o custo computacional de analisar divisores de um por um.

<br>

## ü§ù Pares de N√∫meros Amig√°veis

Os n√∫meros amig√°veis s√£o determinados em pares amigos, dois n√∫meros s√£o considerados **amig√°veis** se a soma dos divisores - exceto ele mesmo - de cada um resulta no outro.

**Exemplo:**  
- Par (220, 284):
  - Divisores de 220: 1, 2, 4, 5, 10, 11, 20, 22, 44, 55, 110, 220
  - Soma dos divisores (exceto ele mesmo): 1 + 2 + 4 + 5 + 10 + 11 + 20 + 22 + 44 + 55 + 110 = 284
  - Divisores de 284: 1, 2, 4, 71, 142
  - Soma dos divisores (exceto ele mesmo): 1 + 2 + 4 + 71 + 142 = 220  
- Portanto, **220 e 284 s√£o amigos**.

Embora existam teoremas que auxiliem no c√°lculo manual de pares, n√£o encontrou-se uma f√≥rmula que permita ganho de desempenho computacional para a identifica√ß√£o de pares amig√°veis em intervalos grandes. 

<br>


## ‚öôÔ∏è Implementa√ß√£o

Nesta se√ß√£o s√£o apresentadas as tr√™s abordagens de implementa√ß√£o desenvolvidas para o projeto: **Sequencial**, **Paralela** e **Distribu√≠da**. Cada abordagem cont√©m a l√≥gica para identifica√ß√£o de **n√∫meros perfeitos** e de **pares de n√∫meros amig√°veis**, por meio de m√©todos, sendo executadas com diferentes intervalos, em uma mesma m√°quina.

### üìè Intervalos

Para atingir intervalos maiores na busca por n√∫meros perfeitos, optou-se por **calcular** os n√∫meros perfeitos em vez de realizar uma varredura direta. A estrat√©gia adotada baseia-se na gera√ß√£o de **primos de Mersenne**, que originam n√∫meros perfeitos.

Assim, o intervalo definido para a fun√ß√£o de n√∫meros perfeitos refere-se ao valor de **p**, que representa o **expoente primo** utilizado para gerar o primo de Mersenne (M‚Çö = 2·µñ ‚àí 1). A partir de **p**, a fun√ß√£o calcula os n√∫meros perfeitos correspondentes, possibilitando a gera√ß√£o de n√∫meros com milhares de d√≠gitos.

Por outro lado, a verifica√ß√£o de **pares de n√∫meros amig√°veis** requer uma varredura **n√∫mero a n√∫mero**, uma vez que n√£o h√° f√≥rmula que permita sua gera√ß√£o direta com efici√™ncia computacional. Nesse caso, o intervalo √© aplicado diretamente ao valor num√©rico a ser testado, sendo realizada a an√°lise completa da soma de divisores e da reciprocidade entre os poss√≠veis pares, mas aplicando melhorias matem√°ticas que proporcionaram melhor desempenho.

#### üìä Tabela de Intervalos Utilizados nos Testes

|  | Intervalo para `p` | Intervalo para Pares Amig√°veis |
|---------|------------------------------------------|----------------------------|
| Teste 1 | At√© 20.000 | At√© 100.000.000 |
| Teste 2 | At√© 12.000 | At√© 50.000.000 |
| Teste 3 | At√© 10.000 | At√© 30.000.000 |

--- 

### üßµ Sequencial

A implementa√ß√£o **sequencial** realiza o processamento utilizando apenas um n√∫cleo de CPU, com execu√ß√£o linear das tarefas.   
O arquivo .java pode ser encontrado neste reposit√≥rio pelo caminho: `/C√≥digos/src/main/java/Sequencial.java`

#### Fun√ß√£o de C√°lculo de N√∫meros Perfeitos:

- √Ä esquerda, a fun√ß√£o respons√°vel por calcular o primo de mersenne a partir de **p** e, ap√≥s, calcular o **n√∫mero perfeito** derivado deste. 
- √Ä direita, uma fun√ß√£o de apoio, que √© respons√°vel por verificar se o n√∫mero √© primo.

| <img src="docs/sequencial/funcao_numeroPerfeito.png" height="200"> | <img src="docs/sequencial/funcao_de_apoio_primo.png" height="200"> |
|:---:|:---:|



#### Fun√ß√£o de Verifica√ß√£o de Pares Amig√°veis:  

- √Ä esquerda, a fun√ß√£o respons√°vel por verificar se a soma de divisores de um n√∫mero √© **rec√≠proca** com outro, determinando **pares amig√°veis**. 
- √Ä direita, uma fun√ß√£o de apoio, que √© respons√°vel por calcular a **soma dos divisores**.

| <img src="docs/sequencial/funcao_buscarParesAmigaveis.png" height="200"> | <img src="docs/sequencial/funcao_de_apoio_somaDivisores.png" height="200"> |
|:---:|:---:|

Para implementar a execu√ß√£o **paralela** e **distribu√≠da** baseou-se na mesma l√≥gica aplicada ao sequencial, fazendo apenas as adapta√ß√µes necess√°rias nas fun√ß√µes citadas.

### üß© Paralela 

 A vers√£o paralela distribui a carga de trabalho entre m√∫ltiplas threads em uma √∫nica m√°quina, explorando a estrat√©gia de Dividir para Conquistar. O m√©todo `main` atua como um orquestrador que "fatia" os intervalos de busca e delega cada fatia para uma thread espec√≠fica. As buscas por n√∫meros perfeitos e amig√°veis s√£o lan√ßadas para rodar simultaneamente, e o `main` aguarda a finaliza√ß√£o de todas as threads (`join`) antes de apresentar os resultados consolidados da busca por n√∫meros amig√°veis.

 **L√≥gica das Threads Paralelas (Runnable)**
 Para alcan√ßar o paralelismo, a l√≥gica de cada busca foi encapsulada em uma classe que implementa a interface `Runnable`, definindo o "plano de trabalho" de cada thread.

 #### Busca por N√∫meros Perfeitos (`threadBuscaPerfeito`)
 A busca pelos expoentes `p` que geram os n√∫meros perfeitos √© dividida entre as threads. Cada thread, ao encontrar um primo de Mersenne, calcula o n√∫mero perfeito correspondente e, na implementa√ß√£o atual, imprime o resultado diretamente no console.

 <img src="docs/paralelo/ThreadBuscaPerfeito.png" height="400">

 *Descri√ß√£o da Imagem:* Classe `threadBuscaPerfeito` que implementa `Runnable`. Ela cont√©m atributos para `numInicial`, `numFinal` e `limiteMax`, e um m√©todo `run()` que itera sobre um intervalo de expoentes `p`. Para cada `p`, verifica se √© primo e, se for, calcula o Primo de Mersenne correspondente (`2^p - 1`). Se o Primo de Mersenne for provavelmente primo, calcula o n√∫mero perfeito derivado (`2^(p-1) * (2^p - 1)`) e o imprime no console.

 #### Busca por Pares Amig√°veis (`threadBuscaAmigavel`)
 A busca por pares amig√°veis tamb√©m √© paralelizada, com cada thread investigando uma fatia do intervalo num√©rico. A efici√™ncia desta busca √© garantida por duas otimiza√ß√µes principais:

 * **Quebra de Simetria:** A verifica√ß√£o `divisores > i` garante que cada par `{a, b}` seja processado apenas uma vez, pelo seu membro menor.
 * **Cache Compartilhado:** Um `Set` concorrente (`amigaveisJaEncontrados`) √© usado para que, quando uma thread encontra um par, ela adicione ambos os n√∫meros a este conjunto. Outras threads consultam este conjunto antes de qualquer c√°lculo pesado e, se o n√∫mero j√° estiver l√°, pulam a verifica√ß√£o.

 <img src="docs/paralelo/ThreadBuscaAmigavel.png" height="400">

 *Descri√ß√£o da Imagem:* Classe `threadBuscaAmigavel` que implementa `Runnable`. Ela possui atributos para `numInicial`, `numFinal`, `limiteMax`, um `Map` para `paresAmigaveis` e um `Set` para `amigaveisJaEncontrados`. O m√©todo `run()` itera sobre o intervalo num√©rico, verifica se o n√∫mero j√° foi encontrado (otimiza√ß√£o de cache), calcula a soma dos divisores e, se encontrar um par amig√°vel rec√≠proco, o adiciona ao `Map` de pares e ao `Set` de encontrados para otimiza√ß√£o futura.

 #### Estruturas de Dados e Sincroniza√ß√£o
 Para garantir a integridade dos dados com m√∫ltiplas threads acessando as cole√ß√µes de resultados ao mesmo tempo, foram utilizadas estruturas de dados "thread-safe":

 * **`ConcurrentSkipListMap`**: Usado para armazenar os pares amig√°veis. Garante acesso concorrente seguro e mant√©m os pares ordenados pela chave (o menor n√∫mero do par).
 * **`ConcurrentHashMap.newKeySet()`**: Usado para o conjunto de otimiza√ß√£o `amigaveisJaEncontrados`. Oferece alt√≠ssima performance para as opera√ß√µes de `add` e `contains`, o que √© crucial para a efici√™ncia da otimiza√ß√£o da busca.

### üåê Distribu√≠da

Na abordagem distribu√≠da, o processamento √© dividido entre m√∫ltiplos clientes, que se conectam a um servidor central via Sockets TCP. Cada cliente recebe um intervalo espec√≠fico de trabalho e executa suas tarefas utilizando m√∫ltiplas threads internas. A distribui√ß√£o dos intervalos √© feita de forma exponencial, favorecendo os primeiros clientes conectados.
<br>
Embora os testes tenham sido realizados na mesma m√°quina, a arquitetura simula um ambiente real distribu√≠do, com m√∫ltiplos processos independentes e comunica√ß√£o em rede. 

#### Divis√£o de Intervalos no Servidor
- A imagem √† esquerda se refere √† distribui√ß√£o do intervalo determinado em sub-intervalos que ser√£o enviados aos clientes.  
- A imagem √† direita se refere √† divis√£o real, no qual esses sub-intervalos ser√£o enviados para os seus respectivos clientes. 

| <img src="docs/distribuido/funcao_distribuirIntervalos.png" height="200"> | <img src="docs/distribuido/divisaoDosIntervalos.png" height="200"> |
|:---:|:---:|

#### Divis√£o de Subintervalos para Threads
- A imagem se refere √† divis√£o do intervalo de cada cliente em sub-intervalos que ser√£o calculados em cada thread.

<img src="docs/distribuido/divisaoThreads.png" height="200"> 

<br>

## üìà An√°lise

Nesta se√ß√£o s√£o apresentados os resultados obtidos nos testes de desempenho para as tr√™s abordagens: **sequencial**, **paralela** e **distribu√≠da**. As compara√ß√µes foram feitas com base no tempo de execu√ß√£o total para diferentes intervalos, considerando tanto n√∫meros perfeitos quanto pares de n√∫meros amig√°veis. Tamb√©m foram realizados testes espec√≠ficos para avaliar a **escalabilidade** das abordagens paralela e distribu√≠da, variando a quantidade de threads e processos.

### üíª Configura√ß√£o da M√°quina

Todos os testes foram realizados na mesma m√°quina, com as seguintes configura√ß√µes. √â importante destacar que, embora a abordagem distribu√≠da normalmente envolva m√∫ltiplos dispositivos, neste projeto todas as execu√ß√µes ocorreram localmente, simulando um ambiente distribu√≠do por meio de m√∫ltiplos processos independentes.

| Componente             | Especifica√ß√£o                                 |
|------------------------|-----------------------------------------------|
| Processador            | Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz     |
| Mem√≥ria RAM            | 8,00 GB                                       |
| Sistema Operacional    | Windows 11 64 bits                            |
| Quantidade de n√∫cleos  | 4                                             |
| Armazenamento          | 477 GB SSD                                    |

### ‚öñÔ∏è Comparativo

A tabela a seguir resume os tempos de execu√ß√£o dos tr√™s c√≥digos para diferentes intervalos de teste.

| | Intervalo Perfeito (p) | Intervalo Amig√°vel (n) | Sequencial | Paralela | Distribu√≠da |
|---------|------------------------|------------------------|-----------------|-------------|----------------|
| Teste 1 | At√© 20.000             | At√© 100.000.000        |     2:30:00     |    47:45    |      37:08     |
| Teste 2 | At√© 12.000             | At√© 50.000.000         |      42:18      |    6:59     |      7:37      |
| Teste 3 | At√© 10.000             | At√© 30.000.000         |     19:45       |    3:18     |       3:20     |

### üìà Teste de Escalabilidade

Os testes de escalabilidade foram realizados com o objetivo de avaliar como o desempenho das abordagens paralela e distribu√≠da varia com o aumento da quantidade de threads e processos.

#### üß© Paralelo

No modelo paralelo, observa-se que o aumento do n√∫mero de threads pode melhorar o desempenho at√© certo ponto. Contudo, ap√≥s determinado limite, o ganho se estabiliza ou at√© mesmo regride, devido √† sobrecarga de gerenciamento das threads e √† limita√ß√£o f√≠sica.

| Threads | Tempo (min) |
|---------|-------------|
| 4       | 8:55        |
| 6       | 6:59        |
| 8       | 8:04        |

#### üåê Distribu√≠do

Na vers√£o distribu√≠da, foram testadas combina√ß√µes variadas de clientes e threads por cliente. Os resultados indicam que o uso de m√∫ltiplos clientes, em conjunto com threads internas, proporciona uma boa divis√£o de carga, com redu√ß√£o significativa do tempo de execu√ß√£o, mesmo em um ambiente local. 

| Threads - Clientes | Tempo (min) |
|--------------------|-------------|
| 2 - 2              | 8:33        |
| 2 - 3              | 7:37        |
| 3 - 2              | 7:13        |
| 2 - 4              | 6:09        |
| 4 - 2              | 6:54        |

### üìù Vis√£o Geral
Os testes realizados visam comparar as tr√™s abordagens distintas. Por meio deles, foi poss√≠vel observar que:
- Na vers√£o **sequencial**, todas as opera√ßoes s√£o realizadas em um √∫nico fluxo de execu√ß√£o, o que resulta em maior tempo de processamento devido √† aus√äncia de paralelismo; <br>
- A implementa√ß√£o **paralela** explora m√∫ltiplas threads dentro de uma mesma m√°quina para dividir o trabalho, permitindo a execu√ß√£o simult√¢nea de v√°rias tarefas e, consequentemente, reduzindo o tempo total de processamento; <br>
- J√° a abordagem **distribu√≠da** simula um ambiente distribu√≠do, onde m√∫ltiplos clientes se conectam a um servidor central via sockets TCP e recebem intervalos de trabalho para processar. Como todas as execu√ß√µes ocorrem em uma √∫nica m√°quina, cada cliente utiliza m√∫ltiplas threads internas para paralelizar seu processamento localmente. Essa combina√ß√£o de distribui√ß√£o entre processos independentes (clientes), paralelismo interno (threads) e divis√£o exponencial de intervalo de n√∫meros perfeitos, permite uma divis√£o eficiente da carga, tornando essa abordagem mais r√°pida que a sequencial e, em muitos casos, at√© mesmo mais eficiente que a paralela tradicional.

<br>

## üìÇ Estrutura dos Arquivos

- **/c√≥digos** ‚Äì Cont√©m o c√≥digo-fonte Java (sequencial, paralelo e distribu√≠do)
- **/docs** ‚Äì Documenta√ß√£o t√©cnica e gr√°ficos de desempenho
- **/outputs** ‚Äì Resultados das execu√ß√µes em diferentes intervalos
- **README.md** ‚Äì Arquivo de descri√ß√£o do projeto

<br>

## üß± Desafios e Solu√ß√µes

 - Desafio: O Limite do Tipo Long

Durante os testes, nos deparamos com uma limita√ß√£o importante: o tipo long, utilizado em muitos c√°lculos, suporta apenas n√∫meros de at√© 19 d√≠gitos. Isso se tornou um obst√°culo, pois trabalhar com n√∫meros extremamente grandes, como os envolvidos na gera√ß√£o de n√∫meros perfeitos, simplesmente n√£o seria poss√≠vel com esse tipo de dado.

- Solu√ß√£o: Euclides-Mersenne e BigInteger

Com a f√≥rmula de Euclides-Mersenne conseguimos contornar esse desafio. Essa f√≥rmula, combinada com o uso do tipo BigInteger, permitiu ultrapassar de forma eficiente o limite do long. Isso foi essencial para alcan√ßar intervalos maiores. Sa√≠mos de um limite de 19 d√≠gitos para n√∫meros que possuem at√© 12.000 d√≠gitos. Ou seja, conseguimos explorar um intervalo mais de 600 vezes maior do que seria poss√≠vel com o long.

## üöÄ Melhorias

- Balanceamento din√¢mico de carga entre clientes atualmente

Cada cliente recebe um intervalo fixo do servidor. Uma melhoria seria implementar um sistema onde quando um cliente termina sua tarefa antes dos outros, ele possa assumir parte da carga de outro cliente ainda execu√ß√£o, evitando que o tempo total dependa do cliente mais lento.

- Retorno de resultados ao servidor na implementa√ß√£o Atual

O servidor apenas distribui os intervalos e n√£o recebe os resultados de volta. Uma melhoria seria permitir que os clientes enviassem no m√≠nimo um aviso de finaliza√ß√£o ao servidor, podendo tamb√©m enviar seus tempos de execu√ß√£o, os pares encontrados e os n√∫meros perfeitos encontrados. Dessa forma haveria um controle centralizado, um monitoramento em tempo real e a possibilidade de consolidar resultados em um √∫nico ponto. 

- Cria√ß√£o din√¢mica de threads com thread pool

A quantidade de threads nos clientes e no c√≥digo paralelo √© definida de forma fixa, assim uma abordagem mais eficiente seria utilizar um Thread Pool, um conjunto de threads reutiliz√°veis controlado dinamicamente. Isso evita o custo de criar e destruir threads repetidamente, reduzindo a sobrecarga e melhorando o uso de CPU.

- Execu√ß√£o realmente distribu√≠da (com m√∫ltiplos computadores) 

Embora a arquitetura seja distribu√≠da, os testes foram feitos em uma √∫nica m√°quina. Uma melhoria importante seria executar os clientes em m√°quinas diferentes, conectadas em rede real, assim tendo paralelismo real entre dispositivos, sem disputa por CPU, resultando em ganhos reais de desempenho.

<br>

## ‚úÖ Conclus√£o

Concluimos que paralelizar j√° traz √≥timos ganhos, e distribuir s√≥ compensa em cargas muito altas. Tamb√©m entendemos que mais threads nem sempre significam mais desempenho. Superamos o limite do long com a f√≥rmula de Euclides-Mersenne, o que foi essencial pra alcan√ßar n√∫meros muito maiores.

